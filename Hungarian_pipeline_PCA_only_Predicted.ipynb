{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipin\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from impyute.imputation.cs import fast_knn\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r'labels.txt',  encoding='utf-8')\n",
    "complete_label_list = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_labeled= pd.read_csv('cleanedHungarian.csv')\n",
    "df_labeled.columns\n",
    "combined_labeled=pd.read_csv('combined_labeled')\n",
    "combined_labeled =pd.concat([combined_labeled,df_labeled])\n",
    "combined_labeled.to_csv('combined_labeled', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_labeled.drop(axis = 1, labels = \"58 num: diagnosis of heart disease (angiographic disease status)\")\n",
    "X = X.drop(axis=1, labels= complete_label_list[58:68])\n",
    "X=X.dropna(axis =1, thresh = 50)\n",
    "\n",
    "Y_arteries = df_labeled[complete_label_list[58:68]] \n",
    "Y_arteries = Y_arteries.replace(to_replace = np.NAN, value = 0)\n",
    "\n",
    "Y_target=df_labeled[complete_label_list[57]]\n",
    "Y_target=Y_target.replace(2,1)\n",
    "Y_target=Y_target.replace(3,1)\n",
    "Y_target=Y_target.replace(4,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[]\n",
    "categorical_features=[]\n",
    "numeric_features=[]\n",
    "columns=X.columns\n",
    "for ho in columns:\n",
    "    if \"1 =\" in ho:\n",
    "        categorical_features.append(ho)\n",
    "    else:\n",
    "        numeric_features.append(ho)\n",
    "categorical_features.append('9 cp: chest pain type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['59 lmt', '60 ladprox', '61 laddist', '62 diag', '63 cxmain',\n",
       "       '64 ramus', '65 om1', '66 om2', '67 rcaprox', '68 rcadist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X=fast_knn(X.values.astype(float), k=30) \n",
    "Y_arteries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),('scaler', StandardScaler())])\n",
    "categorical_transformer= Pipeline(steps=[('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #not in use\n",
    "# def likelihood(top, bottom):\n",
    "#     if bottom==0:\n",
    "#         return 1\n",
    "#     return (top+1)/bottom\n",
    "\n",
    "# def recall(confusion_matrix):\n",
    "#     column_sum = np.sum(confusion_matrix, axis=0)\n",
    "#     num=0\n",
    "#     conditional_probability=1\n",
    "#     while num < len(confusion_matrix.T):\n",
    "#         conditional_probability=conditional_probability+(confusion_matrix[num][num]+1)/confusion_matrix.sum()*likelihood(confusion_matrix[num][num],column_sum[num])\n",
    "#         num=num+1\n",
    "#     return conditional_probability\n",
    "artery_recall =pd.DataFrame(columns = [\"ANN\", \"SVM\", \"Tree\", \"NB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_SVM= Pipeline(steps=[('preprocessor', preprocessor),('pca1', PCA(n_components=5)),('clf_SVM',SVC(kernel = 'linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ANN= Pipeline(steps=[('preprocessor', preprocessor),('pca1', PCA(n_components=5)),('ANN',MLPClassifier(solver='lbfgs', activation = 'logistic', hidden_layer_sizes = (500)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_DT= Pipeline(steps=[('preprocessor', preprocessor),('pca1', PCA(n_components=5)), ('clf_gini',DecisionTreeClassifier(criterion='gini'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_NB= Pipeline(steps=[('preprocessor', preprocessor),('pca1', PCA(n_components=5)),('clf_NB',GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_Rf = Pipeline(steps=[('clf_RF_ext', RandomForestClassifier(max_depth=10000, random_state=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [pipeline_SVM, pipeline_ANN, pipeline_DT, pipeline_NB]\n",
    "pipeline_dict= {0:\"SVM\",1:\"ANN\",2:\"DT\",3:\"NB\"}\n",
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NB', 'NB', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM', 'SVM']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['59 lmt', '60 ladprox', '61 laddist', '62 diag', '63 cxmain',\n",
       "       '64 ramus', '65 om1', '66 om2', '67 rcaprox', '68 rcadist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=[]\n",
    "for artery in Y_arteries.columns:\n",
    "    #norm = \n",
    "    best_accuracy=0.0\n",
    "    best_classifier=0\n",
    "    best_pipeline=\"\"\n",
    "    accuracies=[]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y_arteries[artery], test_size = 0.3,stratify = Y_arteries[artery])\n",
    "    for pipe in pipelines:\n",
    "        pipe.fit(X_train, Y_train)\n",
    "     \n",
    "    accuracies.append(artery)\n",
    "    #checking accuracy\n",
    "    #for i,model in enumerate(pipelines):\n",
    "        #print(\"{} Test Accuracy: {}\".format(pipeline_dict[i], model.score(X_test,Y_test)))\n",
    "    for i,model in enumerate(pipelines):\n",
    "        if model.score(X_test,Y_test)> best_accuracy:\n",
    "            best_accuracy=model.score(X_test,Y_test)\n",
    "            best_pipeline=model\n",
    "            best_classifier =i\n",
    "    arr.append(format(pipeline_dict[best_classifier]))\n",
    "    \n",
    "    predicted = pipelines[i].predict(X)\n",
    "    df[artery]= predicted\n",
    "print(arr)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment\n",
    "#df.drop(columns=['60 ladprox', '67 rcaprox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Experiment\n",
    "#df.drop(columns=['60 ladprox', '67 rcaprox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training for second tier\n",
    "#pipeline_RF_PCA=Pipeline([('scalar5',StandardScaler()), ('pca5', PCA(n_components=3)),('clf_Rf',RandomForestClassifier(max_depth=10000, random_state=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_SVM= Pipeline(steps=[('clf_SVM',SVC(kernel = 'linear'))])\n",
    "pipeline_ANN= Pipeline(steps=[('ANN',MLPClassifier(solver='lbfgs', activation = 'logistic', hidden_layer_sizes = (500)))])\n",
    "pipeline_DT= Pipeline(steps=[('clf_gini',DecisionTreeClassifier(criterion='gini'))])\n",
    "pipeline_Rf = Pipeline(steps=[('clf_RF_ext', RandomForestClassifier(max_depth=10000, random_state=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [pipeline_SVM, pipeline_ANN, pipeline_DT, pipeline_Rf]\n",
    "pipeline_dict= {0:\"SVM\",1:\"ANN\",2:\"DT\",3:\"RF\"}\n",
    "df_mean= pd.DataFrame(columns=[\"Iteration\",\"SVM\",\"ANN\",\"DT\",\"RF\"])\n",
    "df_score=pd.read_csv(r'58_using_predicted_PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.7457627118644068\n",
      "ANN Test Accuracy: 0.7288135593220338\n",
      "DT Test Accuracy: 0.7457627118644068\n",
      "RF Test Accuracy: 0.7457627118644068\n",
      "\n",
      "\n",
      "[0, 0.7457627118644068, 0.7288135593220338, 0.7457627118644068, 0.7457627118644068]\n",
      "SVM Test Accuracy: 0.7796610169491526\n",
      "ANN Test Accuracy: 0.7796610169491526\n",
      "DT Test Accuracy: 0.7288135593220338\n",
      "RF Test Accuracy: 0.7457627118644068\n",
      "\n",
      "\n",
      "[1, 0.7796610169491526, 0.7796610169491526, 0.7288135593220338, 0.7457627118644068]\n",
      "SVM Test Accuracy: 0.7288135593220338\n",
      "ANN Test Accuracy: 0.7288135593220338\n",
      "DT Test Accuracy: 0.7288135593220338\n",
      "RF Test Accuracy: 0.7288135593220338\n",
      "\n",
      "\n",
      "[2, 0.7288135593220338, 0.7288135593220338, 0.7288135593220338, 0.7288135593220338]\n",
      "SVM Test Accuracy: 0.7796610169491526\n",
      "ANN Test Accuracy: 0.7796610169491526\n",
      "DT Test Accuracy: 0.7796610169491526\n",
      "RF Test Accuracy: 0.7796610169491526\n",
      "\n",
      "\n",
      "[3, 0.7796610169491526, 0.7796610169491526, 0.7796610169491526, 0.7796610169491526]\n",
      "SVM Test Accuracy: 0.7966101694915254\n",
      "ANN Test Accuracy: 0.8135593220338984\n",
      "DT Test Accuracy: 0.7796610169491526\n",
      "RF Test Accuracy: 0.7627118644067796\n",
      "\n",
      "\n",
      "[4, 0.7966101694915254, 0.8135593220338984, 0.7796610169491526, 0.7627118644067796]\n",
      "SVM Test Accuracy: 0.6610169491525424\n",
      "ANN Test Accuracy: 0.6610169491525424\n",
      "DT Test Accuracy: 0.6610169491525424\n",
      "RF Test Accuracy: 0.6779661016949152\n",
      "\n",
      "\n",
      "[5, 0.6610169491525424, 0.6610169491525424, 0.6610169491525424, 0.6779661016949152]\n",
      "SVM Test Accuracy: 0.6949152542372882\n",
      "ANN Test Accuracy: 0.6949152542372882\n",
      "DT Test Accuracy: 0.6949152542372882\n",
      "RF Test Accuracy: 0.6949152542372882\n",
      "\n",
      "\n",
      "[6, 0.6949152542372882, 0.6949152542372882, 0.6949152542372882, 0.6949152542372882]\n",
      "SVM Test Accuracy: 0.7288135593220338\n",
      "ANN Test Accuracy: 0.7288135593220338\n",
      "DT Test Accuracy: 0.7288135593220338\n",
      "RF Test Accuracy: 0.7288135593220338\n",
      "\n",
      "\n",
      "[7, 0.7288135593220338, 0.7288135593220338, 0.7288135593220338, 0.7288135593220338]\n",
      "SVM Test Accuracy: 0.6779661016949152\n",
      "ANN Test Accuracy: 0.6779661016949152\n",
      "DT Test Accuracy: 0.6779661016949152\n",
      "RF Test Accuracy: 0.6779661016949152\n",
      "\n",
      "\n",
      "[8, 0.6779661016949152, 0.6779661016949152, 0.6779661016949152, 0.6779661016949152]\n",
      "SVM Test Accuracy: 0.6779661016949152\n",
      "ANN Test Accuracy: 0.6779661016949152\n",
      "DT Test Accuracy: 0.6779661016949152\n",
      "RF Test Accuracy: 0.6779661016949152\n",
      "\n",
      "\n",
      "[9, 0.6779661016949152, 0.6779661016949152, 0.6779661016949152, 0.6779661016949152]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#accuracies.append(\"Hungarian\")\n",
    "num=0\n",
    "while num < 10:\n",
    "    accuracies=[]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df,Y_target, test_size = 0.2, stratify = Y_target)\n",
    "    for pipe in pipelines:\n",
    "        pipe.fit(X_train, Y_train)\n",
    "    accuracies.append(num)\n",
    "    #checking accuracy\n",
    "    for i,model in enumerate(pipelines):\n",
    "        print(\"{} Test Accuracy: {}\".format(pipeline_dict[i], model.score(X_test,Y_test)))\n",
    "        accuracies.append(model.score(X_test,Y_test))\n",
    "    print(\"\\n\")\n",
    "    print(accuracies)\n",
    "    df_mean.loc[len(df_mean)]=accuracies\n",
    "    num=num+1\n",
    "print(len(df_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iteration       SVM       ANN        DT        RF\n",
      "0        0.0  0.745763  0.728814  0.745763  0.745763\n",
      "1        1.0  0.779661  0.779661  0.728814  0.745763\n",
      "2        2.0  0.728814  0.728814  0.728814  0.728814\n",
      "3        3.0  0.779661  0.779661  0.779661  0.779661\n",
      "4        4.0  0.796610  0.813559  0.779661  0.762712\n",
      "5        5.0  0.661017  0.661017  0.661017  0.677966\n",
      "6        6.0  0.694915  0.694915  0.694915  0.694915\n",
      "7        7.0  0.728814  0.728814  0.728814  0.728814\n",
      "8        8.0  0.677966  0.677966  0.677966  0.677966\n",
      "9        9.0  0.677966  0.677966  0.677966  0.677966\n"
     ]
    }
   ],
   "source": [
    "print(df_mean)\n",
    "results=np.array\n",
    "results=df_mean.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVM    0.727119\n",
       "ANN    0.727119\n",
       "DT     0.720339\n",
       "RF     0.722034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop(labels='Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dataset       SVM       ANN        DT        RF\n",
      "0    Cleveland  0.768421  0.761404  0.754386  0.764912\n",
      "1    Hungarian  0.737288  0.735593  0.740678  0.740678\n",
      "2    LongBeach  0.750000  0.720000  0.732500  0.742500\n",
      "3  Swizterland  0.920000  0.912000  0.908000  0.916000\n",
      "4          NaN  0.727119  0.727119  0.720339  0.722034\n"
     ]
    }
   ],
   "source": [
    "df_score.loc[len(df_score)]=results\n",
    "print(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_score.to_csv('58_using_predicted_PCA', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
